{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SongGeneratorv2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow and other libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filePath = '/content/drive/MyDrive/Rush Album Lyrics/Permanent Waves/Permanent Waves All Songs.txt' # Just Freewill\n",
        "#filePath = '/content/drive/MyDrive/Rush Album Lyrics/All Lyrics.txt' # All lyrics\n",
        "filePath = '/content/drive/MyDrive/Rush Album Lyrics/All Lyrics For Real.txt' # All lyrics"
      ],
      "metadata": {
        "id": "YPiNbXXv6hEn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(filePath, 'rb').read().decode(encoding='cp1252')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuiBZWNU6sD9",
        "outputId": "8bec915d-9077-466e-9990-cd2b14ae183d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 149243 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGJHugJfE4WM",
        "outputId": "e1cffa74-c066-413a-9d6b-f928c50e2585"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "chars = chars_from_ids(ids)\n",
        "\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "ZuNVs1VDyjCH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids\n",
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n",
        "\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n",
        "\n",
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())\n",
        "\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdf6LBHZtkwe",
        "outputId": "4904ee5c-1498-43c0-aa6a-bacaac1c2abe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y\n",
            "e\n",
            "a\n",
            "h\n",
            ",\n",
            " \n",
            "o\n",
            "h\n",
            " \n",
            "y\n",
            "tf.Tensor(\n",
            "[b'Y' b'e' b'a' b'h' b',' b' ' b'o' b'h' b' ' b'y' b'e' b'a' b'h' b'!'\n",
            " b'\\r' b'\\n' b'O' b'o' b'h' b',' b' ' b's' b'a' b'i' b'd' b' ' b'I' b','\n",
            " b' ' b'I' b\"'\" b'm' b' ' b'c' b'o' b'm' b'i' b'n' b\"'\" b' ' b'o' b'u'\n",
            " b't' b' ' b't' b'o' b' ' b'g' b'e' b't' b' ' b'y' b'o' b'u' b'\\r' b'\\n'\n",
            " b'O' b'o' b'h' b',' b' ' b's' b'i' b't' b' ' b'd' b'o' b'w' b'n' b','\n",
            " b' ' b'I' b\"'\" b'm' b' ' b'c' b'o' b'm' b'i' b'n' b\"'\" b' ' b'o' b'u'\n",
            " b't' b' ' b't' b'o' b' ' b'f' b'i' b'n' b'd' b' ' b'y' b'o' b'u' b'\\r'\n",
            " b'\\n' b'O' b'o'], shape=(101,), dtype=string)\n",
            "tf.Tensor(\n",
            "[b'Y' b'e' b'a' b'h' b',' b' ' b'o' b'h' b' ' b'y' b'e' b'a' b'h' b'!'\n",
            " b'\\r' b'\\n' b'O' b'o' b'h' b',' b' ' b's' b'a' b'i' b'd' b' ' b'I' b','\n",
            " b' ' b'I' b\"'\" b'm' b' ' b'c' b'o' b'm' b'i' b'n' b\"'\" b' ' b'o' b'u'\n",
            " b't' b' ' b't' b'o' b' ' b'g' b'e' b't' b' ' b'y' b'o' b'u' b'\\r' b'\\n'\n",
            " b'O' b'o' b'h' b',' b' ' b's' b'i' b't' b' ' b'd' b'o' b'w' b'n' b','\n",
            " b' ' b'I' b\"'\" b'm' b' ' b'c' b'o' b'm' b'i' b'n' b\"'\" b' ' b'o' b'u'\n",
            " b't' b' ' b't' b'o' b' ' b'f' b'i' b'n' b'd' b' ' b'y' b'o' b'u' b'\\r'\n",
            " b'\\n' b'O' b'o'], shape=(101,), dtype=string)\n",
            "b\"Yeah, oh yeah!\\r\\nOoh, said I, I'm comin' out to get you\\r\\nOoh, sit down, I'm comin' out to find you\\r\\nOo\"\n",
            "b\"h, yeah\\r\\nOoh yeah\\r\\nFindin' my way!\\r\\n\\r\\nI've been gone so long\\r\\nI've lost count of the years\\r\\nWell, I s\"\n",
            "b\"ang some sad songs\\r\\nOh yes, and cried some bad tears\\r\\n\\r\\nLook out! I'm comin', whoa, whoa\\r\\nLook out! I\"\n",
            "b\"'m comin', whoa, yeah\\r\\n\\r\\nI'm runnin', finding my way back home\\r\\nOh yeah!\\r\\n\\r\\nYeah, oh, yeah!\\r\\nOoh, sai\"\n",
            "b\"d I, I'm comin' back to look for you\\r\\nOoh, sit down, I'm goin' by the back door\\r\\nOoh, yeah\\r\\nOoh, yeah\"\n",
            "Input : b\"Yeah, oh yeah!\\r\\nOoh, said I, I'm comin' out to get you\\r\\nOoh, sit down, I'm comin' out to find you\\r\\nO\"\n",
            "Target: b\"eah, oh yeah!\\r\\nOoh, said I, I'm comin' out to get you\\r\\nOoh, sit down, I'm comin' out to find you\\r\\nOo\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Training Set\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K66VVZbguJoG",
        "outputId": "e38a363e-c9a2-407e-9543-314748a36835"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "2-T5pj2Fuo8A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "BaG6zQsKurVV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "0POhieO3uxfd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SqD3dmlu0i2",
        "outputId": "addc8f46-0426-45ec-a152-9ddfb46bead1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 76) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  19456     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  77900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,035,660\n",
            "Trainable params: 4,035,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRUm7TZTvFlW",
        "outputId": "53766adc-ce28-43f0-f387-ac8c7f555915"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\"heavy\\r\\nAnd I just...I just don't understand\\r\\nWhy must my crew desert me?\\r\\nWhen I need...I need a gui\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\nO??\\'li\"/bwMGiO-ZPEHez1(z(\\rOOV)i\":W/wYc4QW2]LMjHF\\rAxPJMF2l3i)S.4\\nBfzh-X)D4.WiI[ynbU[talpFzI.faA!wXju'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "tf.exp(example_batch_mean_loss).numpy()\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3LIGmY2vk6u",
        "outputId": "c6d82e42-2e15-4a55-c602-8489015c73f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 76)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.3304205, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "mjpvt4CGv1QF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQn2xvb9v4kV",
        "outputId": "3eb99ffe-17b0-4674-889b-199b65dd9399"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 198s 8s/step - loss: 3.9794\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 158s 7s/step - loss: 2.9594\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 160s 7s/step - loss: 2.5455\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 160s 7s/step - loss: 2.3416\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 163s 7s/step - loss: 2.2497\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 160s 7s/step - loss: 2.1848\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 161s 7s/step - loss: 2.1219\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 157s 7s/step - loss: 2.0629\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 156s 7s/step - loss: 2.0048\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 152s 7s/step - loss: 1.9447\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 153s 7s/step - loss: 1.8871\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 158s 7s/step - loss: 1.8287\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 163s 7s/step - loss: 1.7737\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 161s 7s/step - loss: 1.7205\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 161s 7s/step - loss: 1.6669\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 161s 7s/step - loss: 1.6139\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 159s 7s/step - loss: 1.5586\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 157s 7s/step - loss: 1.5056\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 159s 7s/step - loss: 1.4546\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 159s 7s/step - loss: 1.4010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "uDu4M2ZSwCcl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "sv1fqrvczXTP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Salesman'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNESIe7Mzdg-",
        "outputId": "090783dd-5250-4085-bf26-fd7291e98f7e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salesmand me sone\r\n",
            "The goozest frize\r\n",
            "Doess ape too liffer\r\n",
            "And like to ros tom of wind man\r\n",
            "Salving things the ske\r\n",
            "The icertems ame wanter\r\n",
            "I well yes tomy about the faue\r\n",
            "\r\n",
            "Haught and dagrentule?\r\n",
            "Nomobring that's the blurse\r\n",
            "Strimitions\r\n",
            "Con't remoment soint hed the swakes the finare\r\n",
            "Ind vistion or a know plowing brod good\r\n",
            "And to yound to key\r\n",
            "At the toung that sobety\r\n",
            "Shates and living eppatade\r\n",
            "Nowhite starts on the bor hal sex, vit by his banyther\r\n",
            "One don't leave to devears of the toperga\r\n",
            "\r\n",
            "Housing adain that pass premaliots of the wildint you\r\n",
            "Ons taves\r\n",
            "Mymortars shait of faith\r\n",
            "Wo to the aun and firad explaze\r\n",
            "\r\n",
            "We ofmahs mere benowe\r\n",
            "That's fight a flow\r\n",
            "\r\n",
            "The but and they remort some around\r\n",
            "You was a need\r\n",
            "Ter consies, fen we as the warful too mus\r\n",
            "Res there's not away\r\n",
            "\r\n",
            "Driven of sermoring\r\n",
            "Miding class\r\n",
            "Exer fays\r\n",
            "Pof it our gespact\r\n",
            "\r\n",
            "I wat a things hera..\r\n",
            "\r\n",
            "Face and time on the downeal of parston\r\n",
            "Peews of purning dangs\r\n",
            "With the sun of the Near\r\n",
            "\r\n",
            "I'll still \"Treel tire \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.18096137046814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz83XSVWz66U",
        "outputId": "85f48892-cd53-47d8-c4b0-626754c16b67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f6efbe085d0>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['In the constellation of Orion'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOUbARk0z74Y",
        "outputId": "8c3257f7-b860-4d06-8988-a70b6be01fe0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the constellation of Orion rise\r\n",
            "Dream is offor hem sandss fass\r\n",
            "All burful and frezess are only\r\n",
            "But in the city back of wind\r\n",
            "I juns a mander lives got a freeent that down\r\n",
            "Well, you can shime out it and down\r\n",
            "\r\n",
            "ISbide's no seads of the light\r\n",
            "\r\n",
            "Sometimes wallitize\r\n",
            "I'm hass so many a feel\r\n",
            "We move me ours day the for chile in the wind blood\r\n",
            "Load new winning bazy\r\n",
            "Plause of poldstiglls\r\n",
            "\r\n",
            "So mpant the pares\r\n",
            "\r\n",
            "[Chorust is so turn\r\n",
            "Thy potrous with shat a flace his pasin away\r\n",
            "Havitions are now fouce that's sather\r\n",
            "Flows a finst appansadity\r\n",
            "Alaunst the sight, I said head\r\n",
            "Whee the reachant mitice\r\n",
            "Gight's gopre a fight\r\n",
            "At seess to less to the fun time\r\n",
            "Is their days to relear\r\n",
            "Is the whoods tha plail\r\n",
            "Her thomeds from the air\r\n",
            "I sun to the fat of thim me is thingel\r\n",
            "We feels than storay spind is head, bood-by night\r\n",
            "The dirf of circlet you thains\r\n",
            "I'm night this was and moanden dancer\r\n",
            "Excin alone soncess of they tod others\r\n",
            "I son cat me sook appo ander\r\n",
            "I fink will helo?\r\n",
            "Oo learn to be to down\r\n",
            "Seillorg c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['Whammy'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub1QoiTFfPGd",
        "outputId": "13fafd86-c8ba-4a51-945f-41933606ab95"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whammy\r\n",
            "\r\n",
            "I'm roining to flaghing controts\r\n",
            "\r\n",
            "An way fle weman tonger\r\n",
            "It's home tolay, what' the Maddles\r\n",
            "That is a dain that's joarned undery\r\n",
            "You know peapso plistinc\r\n",
            "Back we are blyone\r\n",
            "On the speer sould of life is need\r\n",
            "We're of the seeser kiver\r\n",
            "For the gets a reals\r\n",
            "That soung so know, shent\r\n",
            "Withos the copiraines\r\n",
            "Whit so landing what they sand they\r\n",
            "Roulinger to yeah\r\n",
            "My said it soue\r\n",
            "The crocks ban the froting dicirstand\r\n",
            "I wann through to be know \r\n",
            "Tuth -ome beands toudd\r\n",
            "A sendan?\r\n",
            "Sometimes residies reasuins\r\n",
            "To find, rus, hat the in\r\n",
            "To over the wire\r\n",
            "Those the scy veings\r\n",
            "But sown the soads you benue\r\n",
            "The proadless mackless alanes\r\n",
            "The tireless that capre againstod\r\n",
            "To my need it's fool to foo sur\r\n",
            "With it eness toores\r\n",
            "To deef is a mist road\r\n",
            "In the flowing for the back\r\n",
            "Well hot my head at all oh\r\n",
            "\r\n",
            "What it is a stire\r\n",
            "Don't wance unlisions they much, nourds\r\n",
            "In the fatter of me\r\n",
            "Citer toos After of they all too mover face\r\n",
            "And the stakss of the tandes fromed\r\n",
            "For the look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['I can feel it in my head'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA6KMWaUfp_c",
        "outputId": "7a1e539b-c7c5-42af-8be8-8044fd7de4af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can feel it in my head\r\n",
            "Guting that still it again the scomptime\r\n",
            "Mysterion wenaille with you rade\r\n",
            "\r\n",
            "Just of the fight?\r\n",
            "Carred the suck is the to excool\r\n",
            "That's mation\r\n",
            "Justivere are by thought on a wirlowor iseag\r\n",
            "Would be winds the sture\r\n",
            "Its a for so uland alove?\r\n",
            "Sole are burn touch of the sinnals of sate\r\n",
            "By wear for the aif\r\n",
            "\r\n",
            "What I feal, believe in my surmor\r\n",
            "Rearons of the way bottle hise\r\n",
            "Justs rolling on the secory of sime\r\n",
            "Waselvilled of imentainstand in mision\r\n",
            "That ingained to the sthees\r\n",
            "Tight away makes af heave for the Bright\r\n",
            "Whilain the world wenes\r\n",
            "If the every prefce gave\r\n",
            "Bubed af anning bagn of the wirlin'\r\n",
            "I sal must leff thered wis ows\r\n",
            "Whe halalipe of rifirs\r\n",
            "And the dark of clased\r\n",
            "It just to clo\r\n",
            "\r\n",
            "I've hid mandin...\r\n",
            "\r\n",
            "Everywayts, chost is try to ungin\r\n",
            "Over is between down the bloods\r\n",
            "More on my whey we are amagit\r\n",
            "\r\n",
            "To that sworld been...\r\n",
            "\r\n",
            "We ad I gut burting fate\r\n",
            "\r\n",
            "Now feed and for s dunt-resples every\r\n",
            "And ralitiveeds\r\n",
            "I'm not we'dly look abone the desserfly insidet\r\n",
            "\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['Sean Smith is'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp1mF4y8iCJX",
        "outputId": "10c195b8-1243-47ec-c439-4282c4e054d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sean Smith is early meaching ron around in your streed\r\n",
            "\r\n",
            "Don't day a fun changer gial fitrind\r\n",
            "The out han's endays upen all cave to slay\r\n",
            "Ragain it a mander flacks\r\n",
            "\r\n",
            "Tryin'd was it wime usways.\r\n",
            "Or inmickoon one dirdon on the arget?\r\n",
            "A sun find out to Becise\r\n",
            "Momeny pall me firtervers, hand\r\n",
            "A perzence things I'd readly for a world on the wellw\r\n",
            "Fres to as in the rain\r\n",
            "A feat of the bester somether\r\n",
            "Whome it what you're babring\r\n",
            "To be afrood in just immire\r\n",
            "\r\n",
            "To recience the wine my fate is stleep\r\n",
            "In the stars of hand\r\n",
            "In the s wind empor the spreams of leaving time\r\n",
            "Reagoned chuns\r\n",
            "Walk against us deseretion\r\n",
            "Looking out it's that's field here\r\n",
            "\r\n",
            "Alt bugns the sulder live\r\n",
            "\r\n",
            "Some are the tur\r\n",
            "That clEader to restectrounce\r\n",
            "I wheels strees abait the fornersla\r\n",
            "Cut's somethen froming choods at sole can ranare\r\n",
            "A gring of me conico\r\n",
            "Becouse to mantel phouss\r\n",
            "Just an a macing oors paint his is gos from plases\r\n",
            "\r\n",
            "Same alredont the notory prizing of the surmunger consusions\r\n",
            "Ons the Adge of a foo co\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['Brandon is'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZqOwqbgiGOO",
        "outputId": "08a2eff3-350b-4725-a55c-73eee2824a7c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brandon is the Time\r\n",
            "Mopented and fained\r\n",
            "In the sperest bock that sein in\r\n",
            "The comestation\r\n",
            "Make a smy soulfrions\r\n",
            "\r\n",
            "Can't hold how at mavell no shor\r\n",
            "To the you ne evered tade\r\n",
            "To le knead-of high\r\n",
            "Head, her hid is room and fall\r\n",
            "Bur the theeding on the ipeenst tlabl\r\n",
            "\r\n",
            "I could be something morest on a world thing\r\n",
            "It's the spansed sways\r\n",
            "\r\n",
            "Now it should\r\n",
            "Rathered of icmored\r\n",
            "Just against the wivet wish so eare your fees\r\n",
            "Looking for ever cons emotion\r\n",
            "Hiswering on a showing life\r\n",
            "Drifting down, fol Oh dog yearly's notche\r\n",
            "I would wands han blind\r\n",
            "Oh, me lot go...\r\n",
            "It gets to explomes in our spreezs\r\n",
            "I sun a with the tames\r\n",
            "Fore and here span around wheil disibstands\r\n",
            "They end fine to arm gytom\r\n",
            "Or face a ginace\r\n",
            "\r\n",
            "It's just tokelend, behind in ot...Lofting evert of the given\r\n",
            "For the worad of aggee\r\n",
            "His miribres myst fight\r\n",
            "In it you get esisune\r\n",
            "Too make the blouds thaveI never side\r\n",
            "\r\n",
            "Now the fremont criss of feet\r\n",
            "\r\n",
            "Wearshing nobody rensevies\r\n",
            "Allied these sands sears\r\n",
            "Row the seams we sun\n"
          ]
        }
      ]
    }
  ]
}